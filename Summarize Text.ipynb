{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-31T07:12:22.290504Z",
     "start_time": "2024-05-31T07:12:22.281138Z"
    }
   },
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "base_url = os.environ.get('OPENAI_BASE_URL')\n",
    "api_key = os.environ.get('OPENAI_API_KEY')\n",
    "model_name = os.environ.get('OPENAI_MODEL_NAME')"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T07:12:24.552380Z",
     "start_time": "2024-05-31T07:12:22.292512Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_openai import OpenAI\n",
    "\n",
    "llm = OpenAI(api_key=api_key, model_name=model_name, base_url=base_url)"
   ],
   "id": "64e5f45104f495b6",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T07:12:24.560177Z",
     "start_time": "2024-05-31T07:12:24.554399Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open('./be-good-and-how-not-to-die.txt', 'r') as file:\n",
    "    article = file.read()"
   ],
   "id": "8d06c8274af73db6",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T07:12:24.569959Z",
     "start_time": "2024-05-31T07:12:24.562188Z"
    }
   },
   "cell_type": "code",
   "source": "print(type(article))",
   "id": "49567f187a622174",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T07:12:24.580703Z",
     "start_time": "2024-05-31T07:12:24.571969Z"
    }
   },
   "cell_type": "code",
   "source": "print(article[:285])",
   "id": "1c9a3fae9e12ff44",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Be good\n",
      "\n",
      "April 2008(This essay is derived from a talk at the 2008 Startup School.)About a month after we started Y Combinator we came up with the\n",
      "phrase that became our motto: Make something people want.  We've\n",
      "learned a lot since then, but if I were choosing now that's still\n",
      "the one \n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T07:12:24.803414Z",
     "start_time": "2024-05-31T07:12:24.581711Z"
    }
   },
   "cell_type": "code",
   "source": "num_token = llm.get_num_tokens(article)",
   "id": "f791d032882d2803",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T07:12:24.829150Z",
     "start_time": "2024-05-31T07:12:24.804441Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    separators=['\\n\\n', '\\n'],\n",
    "    chunk_size=5000,\n",
    "    chunk_overlap=500\n",
    ")"
   ],
   "id": "1bdd4debbeac9e62",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T07:12:24.834889Z",
     "start_time": "2024-05-31T07:12:24.830166Z"
    }
   },
   "cell_type": "code",
   "source": "article_chunks = text_splitter.create_documents([article])",
   "id": "3f1fe4c5a0e76ebe",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T07:12:24.846588Z",
     "start_time": "2024-05-31T07:12:24.835900Z"
    }
   },
   "cell_type": "code",
   "source": "print(f\"You have {len(article_chunks)} chunks instead of 1\")",
   "id": "83478521e75136b0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have 8 chunks instead of 1\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T07:18:09.390219Z",
     "start_time": "2024-05-31T07:18:09.382906Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.chains.summarize import load_summarize_chain\n",
    "\n",
    "summarize_chain = load_summarize_chain(llm = llm,chain_type= \"map_reduce\")\n",
    "stream = summarize_chain.stream(article_chunks)"
   ],
   "id": "ddac33a29d34ef84",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T07:19:27.807692Z",
     "start_time": "2024-05-31T07:18:18.466148Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for sentence in stream:\n",
    "    print(sentence)"
   ],
   "id": "9271f3b017d9b152",
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[14], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43msentence\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mstream\u001B[49m\u001B[43m:\u001B[49m\n\u001B[0;32m      2\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mprint\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43msentence\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Worskspace\\langchain-learning\\venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:808\u001B[0m, in \u001B[0;36mRunnable.stream\u001B[1;34m(self, input, config, **kwargs)\u001B[0m\n\u001B[0;32m    798\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mstream\u001B[39m(\n\u001B[0;32m    799\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    800\u001B[0m     \u001B[38;5;28minput\u001B[39m: Input,\n\u001B[0;32m    801\u001B[0m     config: Optional[RunnableConfig] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m    802\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Optional[Any],\n\u001B[0;32m    803\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Iterator[Output]:\n\u001B[0;32m    804\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    805\u001B[0m \u001B[38;5;124;03m    Default implementation of stream, which calls invoke.\u001B[39;00m\n\u001B[0;32m    806\u001B[0m \u001B[38;5;124;03m    Subclasses should override this method if they support streaming output.\u001B[39;00m\n\u001B[0;32m    807\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 808\u001B[0m     \u001B[38;5;28;01myield\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minvoke\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Worskspace\\langchain-learning\\venv\\Lib\\site-packages\\langchain\\chains\\base.py:166\u001B[0m, in \u001B[0;36mChain.invoke\u001B[1;34m(self, input, config, **kwargs)\u001B[0m\n\u001B[0;32m    164\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    165\u001B[0m     run_manager\u001B[38;5;241m.\u001B[39mon_chain_error(e)\n\u001B[1;32m--> 166\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\n\u001B[0;32m    167\u001B[0m run_manager\u001B[38;5;241m.\u001B[39mon_chain_end(outputs)\n\u001B[0;32m    169\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m include_run_info:\n",
      "File \u001B[1;32m~\\Worskspace\\langchain-learning\\venv\\Lib\\site-packages\\langchain\\chains\\base.py:156\u001B[0m, in \u001B[0;36mChain.invoke\u001B[1;34m(self, input, config, **kwargs)\u001B[0m\n\u001B[0;32m    153\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    154\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_inputs(inputs)\n\u001B[0;32m    155\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m--> 156\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrun_manager\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    157\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m new_arg_supported\n\u001B[0;32m    158\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call(inputs)\n\u001B[0;32m    159\u001B[0m     )\n\u001B[0;32m    161\u001B[0m     final_outputs: Dict[\u001B[38;5;28mstr\u001B[39m, Any] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprep_outputs(\n\u001B[0;32m    162\u001B[0m         inputs, outputs, return_only_outputs\n\u001B[0;32m    163\u001B[0m     )\n\u001B[0;32m    164\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "File \u001B[1;32m~\\Worskspace\\langchain-learning\\venv\\Lib\\site-packages\\langchain\\chains\\combine_documents\\base.py:137\u001B[0m, in \u001B[0;36mBaseCombineDocumentsChain._call\u001B[1;34m(self, inputs, run_manager)\u001B[0m\n\u001B[0;32m    135\u001B[0m \u001B[38;5;66;03m# Other keys are assumed to be needed for LLM prediction\u001B[39;00m\n\u001B[0;32m    136\u001B[0m other_keys \u001B[38;5;241m=\u001B[39m {k: v \u001B[38;5;28;01mfor\u001B[39;00m k, v \u001B[38;5;129;01min\u001B[39;00m inputs\u001B[38;5;241m.\u001B[39mitems() \u001B[38;5;28;01mif\u001B[39;00m k \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minput_key}\n\u001B[1;32m--> 137\u001B[0m output, extra_return_dict \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcombine_docs\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    138\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdocs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m_run_manager\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_child\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mother_keys\u001B[49m\n\u001B[0;32m    139\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    140\u001B[0m extra_return_dict[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moutput_key] \u001B[38;5;241m=\u001B[39m output\n\u001B[0;32m    141\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m extra_return_dict\n",
      "File \u001B[1;32m~\\Worskspace\\langchain-learning\\venv\\Lib\\site-packages\\langchain\\chains\\combine_documents\\map_reduce.py:226\u001B[0m, in \u001B[0;36mMapReduceDocumentsChain.combine_docs\u001B[1;34m(self, docs, token_max, callbacks, **kwargs)\u001B[0m\n\u001B[0;32m    214\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcombine_docs\u001B[39m(\n\u001B[0;32m    215\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    216\u001B[0m     docs: List[Document],\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    219\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any,\n\u001B[0;32m    220\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[\u001B[38;5;28mstr\u001B[39m, \u001B[38;5;28mdict\u001B[39m]:\n\u001B[0;32m    221\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Combine documents in a map reduce manner.\u001B[39;00m\n\u001B[0;32m    222\u001B[0m \n\u001B[0;32m    223\u001B[0m \u001B[38;5;124;03m    Combine by mapping first chain over all documents, then reducing the results.\u001B[39;00m\n\u001B[0;32m    224\u001B[0m \u001B[38;5;124;03m    This reducing can be done recursively if needed (if there are many documents).\u001B[39;00m\n\u001B[0;32m    225\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 226\u001B[0m     map_results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mllm_chain\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    227\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;66;43;03m# FYI - this is parallelized and so it is fast.\u001B[39;49;00m\n\u001B[0;32m    228\u001B[0m \u001B[43m        \u001B[49m\u001B[43m[\u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdocument_variable_name\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43md\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpage_content\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m}\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43md\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mdocs\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    229\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    230\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    231\u001B[0m     question_result_key \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mllm_chain\u001B[38;5;241m.\u001B[39moutput_key\n\u001B[0;32m    232\u001B[0m     result_docs \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m    233\u001B[0m         Document(page_content\u001B[38;5;241m=\u001B[39mr[question_result_key], metadata\u001B[38;5;241m=\u001B[39mdocs[i]\u001B[38;5;241m.\u001B[39mmetadata)\n\u001B[0;32m    234\u001B[0m         \u001B[38;5;66;03m# This uses metadata from the docs, and the textual results from `results`\u001B[39;00m\n\u001B[0;32m    235\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m i, r \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(map_results)\n\u001B[0;32m    236\u001B[0m     ]\n",
      "File \u001B[1;32m~\\Worskspace\\langchain-learning\\venv\\Lib\\site-packages\\langchain\\chains\\llm.py:251\u001B[0m, in \u001B[0;36mLLMChain.apply\u001B[1;34m(self, input_list, callbacks)\u001B[0m\n\u001B[0;32m    249\u001B[0m     run_manager\u001B[38;5;241m.\u001B[39mon_chain_error(e)\n\u001B[0;32m    250\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\n\u001B[1;32m--> 251\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcreate_outputs\u001B[49m\u001B[43m(\u001B[49m\u001B[43mresponse\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    252\u001B[0m run_manager\u001B[38;5;241m.\u001B[39mon_chain_end({\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moutputs\u001B[39m\u001B[38;5;124m\"\u001B[39m: outputs})\n\u001B[0;32m    253\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m outputs\n",
      "File \u001B[1;32m~\\Worskspace\\langchain-learning\\venv\\Lib\\site-packages\\langchain\\chains\\llm.py:281\u001B[0m, in \u001B[0;36mLLMChain.create_outputs\u001B[1;34m(self, llm_result)\u001B[0m\n\u001B[0;32m    279\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcreate_outputs\u001B[39m(\u001B[38;5;28mself\u001B[39m, llm_result: LLMResult) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m List[Dict[\u001B[38;5;28mstr\u001B[39m, Any]]:\n\u001B[0;32m    280\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Create outputs from response.\"\"\"\u001B[39;00m\n\u001B[1;32m--> 281\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43m[\u001B[49m\n\u001B[0;32m    282\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;66;43;03m# Get the text of the top generated string.\u001B[39;49;00m\n\u001B[0;32m    283\u001B[0m \u001B[43m        \u001B[49m\u001B[43m{\u001B[49m\n\u001B[0;32m    284\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moutput_key\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moutput_parser\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparse_result\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgeneration\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    285\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mfull_generation\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mgeneration\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    286\u001B[0m \u001B[43m        \u001B[49m\u001B[43m}\u001B[49m\n\u001B[0;32m    287\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mgeneration\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mllm_result\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerations\u001B[49m\n\u001B[0;32m    288\u001B[0m \u001B[43m    \u001B[49m\u001B[43m]\u001B[49m\n\u001B[0;32m    289\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreturn_final_only:\n\u001B[0;32m    290\u001B[0m         result \u001B[38;5;241m=\u001B[39m [{\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moutput_key: r[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moutput_key]} \u001B[38;5;28;01mfor\u001B[39;00m r \u001B[38;5;129;01min\u001B[39;00m result]\n",
      "File \u001B[1;32m~\\Worskspace\\langchain-learning\\venv\\Lib\\site-packages\\langchain\\chains\\llm.py:284\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    279\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcreate_outputs\u001B[39m(\u001B[38;5;28mself\u001B[39m, llm_result: LLMResult) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m List[Dict[\u001B[38;5;28mstr\u001B[39m, Any]]:\n\u001B[0;32m    280\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Create outputs from response.\"\"\"\u001B[39;00m\n\u001B[0;32m    281\u001B[0m     result \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m    282\u001B[0m         \u001B[38;5;66;03m# Get the text of the top generated string.\u001B[39;00m\n\u001B[0;32m    283\u001B[0m         {\n\u001B[1;32m--> 284\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moutput_key: \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moutput_parser\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparse_result\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgeneration\u001B[49m\u001B[43m)\u001B[49m,\n\u001B[0;32m    285\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfull_generation\u001B[39m\u001B[38;5;124m\"\u001B[39m: generation,\n\u001B[0;32m    286\u001B[0m         }\n\u001B[0;32m    287\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m generation \u001B[38;5;129;01min\u001B[39;00m llm_result\u001B[38;5;241m.\u001B[39mgenerations\n\u001B[0;32m    288\u001B[0m     ]\n\u001B[0;32m    289\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreturn_final_only:\n\u001B[0;32m    290\u001B[0m         result \u001B[38;5;241m=\u001B[39m [{\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moutput_key: r[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moutput_key]} \u001B[38;5;28;01mfor\u001B[39;00m r \u001B[38;5;129;01min\u001B[39;00m result]\n",
      "File \u001B[1;32m~\\Worskspace\\langchain-learning\\venv\\Lib\\site-packages\\langchain_core\\output_parsers\\base.py:221\u001B[0m, in \u001B[0;36mBaseOutputParser.parse_result\u001B[1;34m(self, result, partial)\u001B[0m\n\u001B[0;32m    208\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mparse_result\u001B[39m(\u001B[38;5;28mself\u001B[39m, result: List[Generation], \u001B[38;5;241m*\u001B[39m, partial: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m T:\n\u001B[0;32m    209\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Parse a list of candidate model Generations into a specific format.\u001B[39;00m\n\u001B[0;32m    210\u001B[0m \n\u001B[0;32m    211\u001B[0m \u001B[38;5;124;03m    The return value is parsed from only the first Generation in the result, which\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    219\u001B[0m \u001B[38;5;124;03m        Structured output.\u001B[39;00m\n\u001B[0;32m    220\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 221\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mparse(\u001B[43mresult\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241m.\u001B[39mtext)\n",
      "\u001B[1;31mIndexError\u001B[0m: list index out of range"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "e09d7a44bf0c9582",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
